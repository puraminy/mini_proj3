{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-GAN-CFAR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/puraminy/mini_proj3/blob/master/2_GAN_CFAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rfFXPTztl8fL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8aebd7e5-0dac-45c9-d3bd-9ac74e05ac8a"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n_0j_uVUcqiG",
        "colab_type": "code",
        "outputId": "bde00886-3cba-4150-dc70-e46d7004d29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.contrib.layers as lays\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import tarfile\n",
        "import urllib\n",
        "import pickle\n",
        "import _pickle as cPickle\n",
        "\n",
        "lr = 0.0002\n",
        "num_epochs = 600\n",
        "batch_size = 256\n",
        "\n",
        "base_folder = 'gdrive/My Drive/cfar/'\n",
        "# base_folder = './'\n",
        "\n",
        "data_path = base_folder + 'data/cifar-10-batches-py/{}'\n",
        "\n",
        "# Download weights\n",
        "if not os.path.isdir(base_folder + 'data'):\n",
        "    os.makedirs(base_folder + 'data')\n",
        "if not os.path.isfile(base_folder + 'data/cifar-10-batches-py/data_batch_1'):\n",
        "    print('Downloading the data ...')\n",
        "    import urllib.request\n",
        "    urllib.request.urlretrieve(\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\", \n",
        "                               base_folder + \"data/cifar-10-python.tar.gz\")\n",
        "    \n",
        "    with tarfile.open(base_folder + 'data/cifar-10-python.tar.gz', \"r:gz\") as tar:\n",
        "        tar.extractall(base_folder + 'data/')\n",
        "    os.remove(base_folder + 'data/cifar-10-python.tar.gz')\n",
        "    print('Download is complete !')\n",
        "\n",
        "# unpickle data files\n",
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = cPickle.load(fo, encoding='latin1')\n",
        "    return dict\n",
        "\n",
        "# Load all the data files and stack them together\n",
        "dataset_x = unpickle(data_path.format('data_batch_1'))['data']\n",
        "for i in range(2,6):\n",
        "    dataset_x = np.vstack((dataset_x, unpickle(data_path.format('data_batch_{}'.format(i)))['data']))\n",
        "# calculate the number of batches per epoch\n",
        "batch_per_ep = dataset_x.shape[0]//batch_size\n",
        "\n",
        "\n",
        "def next_batch(batch_number):\n",
        "    # a function to load a bacth of images\n",
        "    batch_x = dataset_x[(batch_number) * batch_size:min([((batch_number) + 1) * batch_size, dataset_x.shape[0]]), :]\n",
        "\n",
        "    # reshape the sample to a batch of images\n",
        "    batch_img = batch_x.reshape((-1, 3, 32, 32))/255.0\n",
        "    batch_img = batch_img.transpose([0, 2, 3, 1])\n",
        "    return batch_img\n",
        "\n",
        "\n",
        "def leaky_relu(x, alpha=0.1):\n",
        "    # Leaky Relu activation function\n",
        "    m_x = tf.nn.relu(-x)\n",
        "    x = tf.nn.relu(x)\n",
        "    x -= alpha * m_x\n",
        "    return x\n",
        "\n",
        "# Define the Generator, a simple CNN with 1 fully connected and 4 convolution layers\n",
        "def generator(inputs, reuse=False):\n",
        "    with tf.variable_scope('generator'):\n",
        "        if reuse:\n",
        "            tf.get_variable_scope().reuse_variables()\n",
        "        net = lays.fully_connected(inputs, 4*4*256, scope='fc1')\n",
        "        net = tf.reshape(net, (batch_size, 4, 4, 256))\n",
        "        net = lays.conv2d_transpose(net, 128, 3, stride=2, scope='conv1', padding='SAME', activation_fn=leaky_relu)\n",
        "        net = lays.conv2d_transpose(net, 64, 3, stride=2, scope='conv2', padding='SAME', activation_fn=leaky_relu)\n",
        "        net = lays.conv2d_transpose(net, 64, 3, stride=2, scope='conv3', padding='SAME', activation_fn=leaky_relu)\n",
        "        net = lays.conv2d(net, 3, 3, scope='conv4', padding='SAME', activation_fn=tf.nn.tanh)\n",
        "        return net\n",
        "\n",
        "\n",
        "# Define the Discriminator, a simple CNN with 3 convolution and 2 fully connected layers\n",
        "def discriminator(inputs, reuse=False):\n",
        "    with tf.variable_scope('discriminator'):\n",
        "        if reuse:\n",
        "            tf.get_variable_scope().reuse_variables()\n",
        "        net = lays.conv2d_transpose(inputs, 64, 3, stride=1, scope='conv1', padding='SAME', activation_fn=leaky_relu)\n",
        "        net = lays.max_pool2d(net, 2, 2, 'SAME', scope='max1')\n",
        "        net = lays.conv2d_transpose(net, 128, 3, stride=1, scope='conv2', padding='SAME', activation_fn=leaky_relu)\n",
        "        net = lays.max_pool2d(net, 2, 2, 'SAME', scope='max2')\n",
        "        net = lays.conv2d_transpose(net, 256, 3, stride=1, scope='conv3', padding='SAME', activation_fn=leaky_relu)\n",
        "        net = lays.max_pool2d(net, 2, 2, 'SAME', scope='max3')\n",
        "        net = tf.reshape(net, (batch_size, 4 * 4 * 256))\n",
        "        net = lays.fully_connected(net, 128, scope='fc1', activation_fn=leaky_relu)\n",
        "        net = lays.dropout(net, 0.5)\n",
        "        net = lays.fully_connected(net, 1, scope='fc2', activation_fn=None)\n",
        "        return net\n",
        "\n",
        "\n",
        "images = tf.placeholder(tf.float32, (batch_size, 32, 32, 3))    # input images\n",
        "z_in = tf.placeholder(tf.float32, (batch_size, 100))            # input noises\n",
        "\n",
        "# Train the discriminator, it tries to discriminate between real and fake (generated) samples\n",
        "outputs_real = discriminator(images)\n",
        "loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(outputs_real), logits=outputs_real))\n",
        "\n",
        "images_fake = generator(z_in)\n",
        "outputs_fake = discriminator(images_fake, reuse=True)\n",
        "loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(outputs_fake), logits=outputs_fake))\n",
        "\n",
        "loss_d = loss_real + loss_fake  # Calculate the total loss\n",
        "discrim_tvars = [var for var in tf.trainable_variables() if var.name.startswith(\"discriminator\")]\n",
        "discrim_train = tf.train.AdamOptimizer(lr).minimize(loss_d, var_list=discrim_tvars)\n",
        "\n",
        "# Train the generator, it tries to fool the discriminator\n",
        "with tf.control_dependencies([discrim_train]):\n",
        "    outputs = discriminator(images_fake, reuse=True)\n",
        "    loss_g = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(outputs), logits=outputs))\n",
        "    gen_tvars = [var for var in tf.trainable_variables() if var.name.startswith(\"generator\")]\n",
        "    gen_train = tf.train.AdamOptimizer(lr).minimize(loss_g, var_list=gen_tvars)\n",
        "\n",
        "# Draw samples from the input distribution as a fixed test set\n",
        "# Can follow how the generator output evolves\n",
        "test_z = np.random.normal(size=(batch_size, 100))\n",
        "\n",
        "# initialize the network\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "restore = False\n",
        "if os.path.isfile(base_folder + 'results/model.ckpt.meta'):\n",
        "  restore = True\n",
        "#   with tf.Session() as sess:\n",
        "    # Restore variables from disk.\n",
        "#     saver.restore(sess, base_folder + 'results/model.ckpt')    \n",
        "    # Check the values of the variables\n",
        "ii = 0\n",
        "if not os.path.isdir(base_folder + 'results'):\n",
        "    os.makedirs(base_folder +'results')\n",
        "else:\n",
        "  import fnmatch\n",
        "  ii = len(fnmatch.filter(os.listdir(base_folder +'results'), '*.png'))\n",
        "  print(\"last index is \", ii)\n",
        "  \n",
        "with tf.Session() as sess:\n",
        "    if restore:\n",
        "      saver = tf.train.import_meta_graph(base_folder +'results/model.ckpt.meta')\n",
        "      saver.restore(sess, base_folder + \"results/model.ckpt\")   \n",
        "      print(\"Model restored.\")\n",
        "    else:  \n",
        "      sess.run(init)\n",
        "    for ep in range(num_epochs):\n",
        "        for batch_n in range(batch_per_ep):  # batches loop\n",
        "            batch_img = next_batch(batch_n)\n",
        "            train_z = np.random.normal(size=(batch_size, 100))\n",
        "\n",
        "            _, gl, dl = sess.run([gen_train, loss_g, loss_d], feed_dict={images: batch_img, z_in: train_z})\n",
        "\n",
        "            if not batch_n%10:\n",
        "               # print('epoch: {} - loss_d: {} - loss_g: {}'.format(ep, dl, gl))\n",
        "               with open(base_folder + 'results/dloss.txt', 'a+') as f:\n",
        "                   print(dl,file=f)\n",
        "               with open(base_folder + 'results/gloss.txt', 'a+') as f:\n",
        "                   print(gl,file=f)\n",
        "        # Save the test results after each Epoch\n",
        "#        print('Testing ...')\n",
        "        images_test = sess.run([images_fake], feed_dict={z_in: test_z})[0]\n",
        "        save_path = saver.save(sess, base_folder + \"results/model.ckpt\")\n",
        "        for i in range(9):\n",
        "            plt.subplot(3, 3, i+1)\n",
        "            plt.imshow(images_test[i])\n",
        "#             plt.show()\n",
        "            plt.savefig(base_folder+ 'results/cfar10-gan-e{}.png'.format(ii))\n",
        "        ii += 1\n",
        "        print('A new test image saved !')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last index is  50\n",
            "INFO:tensorflow:Restoring parameters from gdrive/My Drive/cfar/results/model.ckpt\n",
            "Model restored.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A new test image saved !\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
            "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  \"Adding an axes using the same arguments as a previous axes \"\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A new test image saved !\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}