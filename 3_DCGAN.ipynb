{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-DCGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/puraminy/mini_proj3/blob/master/3_DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jtVw1XxCEtYk",
        "colab_type": "code",
        "outputId": "e81d3dfc-aca7-4da2-d677-7ff8e112c0e8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Reshape, Flatten, Dropout\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "from keras.datasets import mnist\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "m1eJCBEEEtYs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Generator():\n",
        "  \n",
        "    model = Sequential()\n",
        "    model.add(Dense(1024, input_dim=100))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(128*7*7))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))\n",
        "    model.add(UpSampling2D((2, 2)))\n",
        "    model.add(Conv2D(64, kernel_size=(5, 5), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(UpSampling2D((2, 2)))\n",
        "    model.add(Conv2D(1, kernel_size=(5, 5), padding='same'))\n",
        "    model.add(Activation('tanh'))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3k3AiqHeEtYv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Discriminator():\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding='same', input_shape=(28, 28, 1)))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Conv2D(128, kernel_size=(5, 5), strides=(2, 2)))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    \n",
        "    optimizer = Adam(lr=1e-5, beta_1=0.1)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "urqv1RthEtYy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def DCGAN(generator, discriminator):\n",
        "\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(generator)\n",
        "    model.add(discriminator)\n",
        "    \n",
        "    optimizer = Adam(lr=2e-4, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a21G2SABEtY0",
        "colab_type": "code",
        "outputId": "52032046-3a57-4c4c-92a4-26b189f4885e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train.astype('float32')\n",
        "X_test.astype('float32')\n",
        "X_train = X_train / 127.5 - 1.0\n",
        "X_test = X_test / 127.5 - 1.0\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
        "\n",
        "print('X_train shape', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "VPkCns5tEtY3",
        "colab_type": "code",
        "outputId": "17396f60-7c5a-44c5-8218-80bc00662edf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "gan = DCGAN(generator, discriminator)\n",
        "\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "input_size = 100\n",
        "\n",
        "num_batches = int(X_train.shape[0] / batch_size)\n",
        "\n",
        "pbar = tqdm(total=epochs * num_batches)\n",
        "\n",
        "gan_loss = []\n",
        "discriminator_loss = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    for index in range(num_batches):\n",
        "        \n",
        "        pbar.update(1)\n",
        "\n",
        "        # Generative data\n",
        "        noise = np.random.uniform(-1, 1, size=[batch_size, input_size])\n",
        "        generated_data = generator.predict_on_batch(noise)\n",
        "\n",
        "        # Training data chosen from Mnist samples\n",
        "        training_data = X_train[index * batch_size: (index + 1) * batch_size]\n",
        "\n",
        "        X = np.vstack((generated_data, training_data))\n",
        "        y = np.zeros(2 * batch_size)\n",
        "        y[:batch_size] = 1\n",
        "\n",
        "        # Train discriminator\n",
        "        d_loss = discriminator.train_on_batch(x=X, y=y)\n",
        "\n",
        "        # Train generator (Seemingly train GAN but the discriminator in the model is disabled to train.)\n",
        "        noise = np.random.uniform(-1, 1, size=[batch_size, input_size])\n",
        "        y = np.zeros(batch_size)\n",
        "        g_loss = gan.train_on_batch(x=noise, y=y)\n",
        "\n",
        "        discriminator_loss.append(d_loss)\n",
        "        gan_loss.append(g_loss)\n",
        "        \n",
        "        img = generated_images = generator.predict(noise)\n",
        "\n",
        "    # Plot losses\n",
        "    fig = plt.figure(figsize=(10, 5))        \n",
        "    fig.suptitle('epoch: ' + str(epoch + 1))\n",
        "    plt.plot(discriminator_loss, label=\"discriminator's loss\", color='b')\n",
        "    plt.plot(gan_loss, label=\"generator's loss\", color='r')\n",
        "    plt.xlim([0, epochs * num_batches])\n",
        "    plt.legend()\n",
        "    plt.savefig('./dcgan-loss/' + str(epoch + 1) + '.png')\n",
        "    plt.close()      \n",
        "\n",
        "    # Visualize generated data\n",
        "    generated_images = generator.predict(noise)\n",
        "\n",
        "    fig = plt.figure(figsize=(9, 9))        \n",
        "    for i in range(9):\n",
        "        plt.subplot(3, 3, i+1)\n",
        "        img = generated_images[i, :] * 0.5 + 0.5\n",
        "        img = img.reshape((28, 28))\n",
        "        plt.tight_layout()\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.savefig('./dcgan-images/' + str(epoch + 1) + '.png')\n",
        "    plt.close()     \n",
        "        \n",
        "pbar.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 56250/56250 [40:14<00:00, 24.49it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}